import os
import uuid
import wave
import pyaudio
from gtts import gTTS
import pygame
import re
from flask import Flask, jsonify
from google.cloud import storage
import openai
from flask_cors import CORS
import librosa
import numpy as np
import tensorflow as tf
import time
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from scipy.spatial.distance import cosine

app = Flask(__name__)
CORS(app)

# OpenAI API í‚¤
openai.api_key = ''

# GCP ì¸ì¦ ê²½ë¡œ
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = ""
BUCKET_NAME = "a_sample"

# ğŸ“ ì˜¤ë””ì˜¤ ë°ì´í„° í´ë” ê²½ë¡œ
audio_dir = ''

# ë…¹ìŒ ì„¤ì •
CHUNK = 1024
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
RECORD_SECONDS = 10

# â€”â€”â€”â€”â€” íŒŒì¼ëª… ì•ˆì „ ì²˜ë¦¬ í•¨ìˆ˜ â€”â€”â€”â€”â€”
def sanitize(text: str) -> str:
    """íŒŒì¼ëª…ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë³€í™˜ (<> ì œì™¸)"""
    text = text.strip()
    # í—ˆìš©ë˜ì§€ ì•ŠëŠ” ë¬¸ì: \ / * ? : " < > | 
    text = re.sub(r'[\\/*?:"<>|]', "_", text)
    return text or "untitled"

# â€”â€”â€”â€”â€” GCS ì—…ë¡œë“œ í•¨ìˆ˜ â€”â€”â€”â€”â€”
def upload_to_gcs(local_path: str, blob_name: str):
    client = storage.Client()
    bucket = client.bucket(BUCKET_NAME)
    blob = bucket.blob(blob_name)
    blob.upload_from_filename(local_path)
    print(f"âœ… GCS ì—…ë¡œë“œ: gs://{BUCKET_NAME}/{blob_name}")

# â€”â€”â€”â€”â€” TTS ìƒì„±Â·ì¬ìƒÂ·ì—…ë¡œë“œ â€”â€”â€”â€”â€”
def tts_and_play(text: str, safe: str):
    # TTS íŒŒì¼ëª…
    tts_filename = f"EX_{safe}.mp3"
    local_tts = os.path.join(os.path.expanduser("~"), tts_filename)
    # 1) TTS ë³€í™˜
    tts = gTTS(text=text, lang='ko')
    tts.save(local_tts)

    # 2) GCS ì—…ë¡œë“œ
    upload_to_gcs(local_tts, tts_filename)

    # í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥
    txt_filename = f"{safe}.txt"
    local_txt = os.path.join(os.path.expanduser("~"), txt_filename)
    with open(local_txt, "w", encoding="utf-8") as f:
        f.write(text)
    upload_to_gcs(local_txt, txt_filename)

    # 3) ìŠ¤í”¼ì»¤ ì¬ìƒ
    pygame.mixer.init()
    pygame.mixer.music.load(local_tts)
    pygame.mixer.music.play()
    while pygame.mixer.music.get_busy():
        pygame.time.Clock().tick(10)
    time.sleep(1)
    pygame.mixer.music.play()
    while pygame.mixer.music.get_busy():
        pygame.time.Clock().tick(10)
    pygame.mixer.quit()
    print("ğŸ”ˆ ì¬ìƒ ì™„ë£Œ")

# ë°˜ë³µí•™ìŠµ-TTS 
def tts_repeat(text: str, safe: str):

    tts_filename = f"EX_{safe}.mp3"
    local_tts = os.path.join(os.path.expanduser("~"), tts_filename)

    tts = gTTS(text=text, lang='ko')
    tts.save(local_tts)

    pygame.mixer.init()
    pygame.mixer.music.load(local_tts)
    for i in range(10):
        pygame.mixer.music.play()
        while pygame.mixer.music.get_busy():
            pygame.time.Clock().tick(10)  # CPU ë‚­ë¹„ ë°©ì§€
        time.sleep(1)  # 1ì´ˆ ì‰¬ê³  ë‹¤ìŒ ì¬ìƒ
    pygame.mixer.quit()
    print("ğŸ”ˆ ì¬ìƒ ì™„ë£Œ")



# â€”â€”â€”â€”â€” ë…¹ìŒÂ·ì €ì¥Â·ì—…ë¡œë“œ â€”â€”â€”â€”â€”
def record_and_upload(safe: str):
    rec_filename = f"{safe}.wav"
    local_rec = os.path.join(os.path.expanduser("~"), rec_filename)
    p = pyaudio.PyAudio()
    stream = p.open(format=FORMAT,
                    channels=CHANNELS,
                    rate=RATE,
                    input=True,
                    frames_per_buffer=CHUNK)
    print(f"ğŸ™ï¸ {RECORD_SECONDS}ì´ˆê°„ ë…¹ìŒ ì‹œì‘...")
    frames = [stream.read(CHUNK) for _ in range(int(RATE/CHUNK*RECORD_SECONDS))]
    print("â¹ ë…¹ìŒ ì™„ë£Œ")

    stream.stop_stream()
    stream.close()
    p.terminate()

    # WAVë¡œ ì €ì¥
    with wave.open(local_rec, 'wb') as wf:
        wf.setnchannels(CHANNELS)
        wf.setsampwidth(p.get_sample_size(FORMAT))
        wf.setframerate(RATE)
        wf.writeframes(b''.join(frames))
    print(f"ğŸ’¾ ë…¹ìŒ íŒŒì¼ ì €ì¥: {local_rec}")

    # GCS ì—…ë¡œë“œ
    upload_to_gcs(local_rec, rec_filename)




# ğŸµ Mel-spectrogram ì¶”ì¶œ í•¨ìˆ˜
def extract_features(audio_path, target_length=130):
    y, sr = librosa.load(audio_path, sr=None, mono=True)
    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)
    mel_spec_resized = librosa.util.fix_length(mel_spec, size=target_length, axis=-1)
    mel_spec_db = librosa.power_to_db(mel_spec_resized, ref=np.max)
    return mel_spec_db

# ğŸ“š ë°ì´í„° ë¡œë”©
def load_data(audio_dir):
    X, y = [], []
    for label in os.listdir(audio_dir):
        label_dir = os.path.join(audio_dir, label)
        if os.path.isdir(label_dir):
            for filename in os.listdir(label_dir):
                if filename.endswith('.wav'):
                    features = extract_features(os.path.join(label_dir, filename))
                    X.append(features)
                    y.append(label)
    return np.array(X), np.array(y)

# ğŸ§  CNN ëª¨ë¸ í•™ìŠµ
def train_and_save_model():
    X, y = load_data(audio_dir)
    print(f"âœ… Loaded {len(X)} samples")
    le = LabelEncoder()
    y_encoded = le.fit_transform(y)
    X = X[..., np.newaxis]
    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

    model = Sequential([
        Conv2D(64, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)),
        MaxPooling2D((2, 2)),
        Conv2D(128, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Flatten(),
        Dense(128, activation='relu'),
        Dense(len(np.unique(y_encoded)), activation='softmax')
    ])

    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))
    model.save('parrot_speech_model.h5')
    print("âœ… Model trained and saved as 'parrot_speech_model.h5'")
    return le

# ğŸ” ì˜¤ë””ì˜¤ ë¶„ë¥˜
def classify_new_audio(model, audio_path, label_encoder):
    features = extract_features(audio_path)
    features = np.expand_dims(features[..., np.newaxis], axis=0)
    prediction = model.predict(features)
    predicted_idx = np.argmax(prediction, axis=1)
    predicted_label = label_encoder.inverse_transform(predicted_idx)[0]
    return predicted_label

# â€”â€”â€” MFCC ì¶”ì¶œ í•¨ìˆ˜ â€”â€”â€”
def extract_mfcc(file_path: str) -> np.ndarray:
    y, sr = librosa.load(file_path, sr=None)
    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
    return np.mean(mfcc, axis=1)

# â€”â€”â€” ë°œìŒ ìœ ì‚¬ë„ ê³„ì‚° â€”â€”â€”
def compare_pronunciation(ref_path: str, test_path: str) -> float:
    mfcc1 = extract_mfcc(ref_path)
    mfcc2 = extract_mfcc(test_path)
    similarity = 1 - cosine(mfcc1, mfcc2)
    return similarity


# ğŸ’¬ GPT í”¼ë“œë°± ìƒì„±
def get_feedback_from_gpt(word, accuracy):
    percent = int(accuracy * 100) 
    prompt = (
        f"ì•µë¬´ìƒˆê°€ '{word}' ë¼ëŠ” ë‹¨ì–´ë¥¼ ë°œìŒí–ˆìŠµë‹ˆë‹¤. "
        f"AI ëª¨ë¸ì´ íŒë‹¨í•œ ë°œìŒ ì •í™•ë„ëŠ” {percent}%ì…ë‹ˆë‹¤. "
        f"ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•µë¬´ìƒˆì—ê²Œ ì¤„ ìˆ˜ ìˆëŠ” ê°„ë‹¨í•˜ê³  ì¹œê·¼í•œ í”¼ë“œë°± ë¬¸ì¥ì„ ì‘ì„±í•´ì£¼ì„¸ìš”. "
        f"ì˜ˆë¥¼ ë“¤ì–´ 'ë°œìŒì´ ì•„ì£¼ ì¢‹ì•„ìš”!', 'ì¡°ê¸ˆë§Œ ë” ì—°ìŠµí•´ë³¼ê¹Œìš”?' ê°™ì€ í˜•ì‹ìœ¼ë¡œìš”."
    )

    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[{"role": "system", "content": "You are a helpful assistant."},
                  {"role": "user", "content": prompt}],
        max_tokens=60,
        temperature=0.7,
        n=1,
    )
    
    # í”¼ë“œë°± ì²˜ë¦¬
    try:
        # 'choices'ì™€ 'message' ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        feedback = response['choices'][0]['message']['content'].strip()
    except (KeyError, IndexError):
        feedback = "í”¼ë“œë°±ì„ ë°›ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    
    return feedback


# ë ˆë²¨ í…ŒìŠ¤íŠ¸ 
def load_all_words_from_gcs(bucket_name):
    storage_client = storage.Client()
    bucket = storage_client.bucket(bucket_name)
    learned_words = []
    for blob in storage_client.list_blobs(bucket):
        if blob.name.endswith(".txt"):
            text = blob.download_as_text()
            learned_words += [w.strip() for w in text.splitlines() if w.strip()]
    return learned_words

def evaluate_level_with_gpt(words):
    prompt = f"""
ì•„ë˜ëŠ” ì•µë¬´ìƒˆê°€ í•™ìŠµí•œ ë‹¨ì–´ ëª©ë¡ì´ì•¼:
{words}

ì¤‘ë³µëœ ë‹¨ì–´ëŠ” ê°ì•ˆí•´ì„œ ì´ ì•µë¬´ìƒˆì˜ ì–¸ì–´ ìˆ˜ì¤€ì„ 1ì—ì„œ 10ê¹Œì§€ì˜ ë ˆë²¨ë¡œ í‰ê°€í•´ì¤˜.
ìˆ«ìë§Œ í•˜ë‚˜ë¡œ ë‹µí•´ì¤˜.
"""
    resp = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[
            {"role":"system","content":"ë‹¹ì‹ ì€ ì•µë¬´ìƒˆ ì–¸ì–´í•™ìŠµ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role":"user","content":prompt}
        ]
    )
    return int(resp.choices[0].message["content"].strip())

def recommend_words_by_level(level):
    prompt = f"""
ì•µë¬´ìƒˆì˜ ì–¸ì–´ ë ˆë²¨ì´ {level}ì´ì•¼.
ì´ ìˆ˜ì¤€ì— ë§ëŠ” í•œêµ­ì–´ ë‹¨ì–´ ë˜ëŠ” ì§§ì€ ë¬¸ì¥ 5ê°œë¥¼ ì¶”ì²œí•´ì¤˜.
ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë³´ì—¬ì¤˜.
"""
    resp = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[
            {"role":"system","content":"ë‹¹ì‹ ì€ ì•µë¬´ìƒˆ ì–¸ì–´í•™ìŠµ ë‹¨ì–´ ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role":"user","content":prompt}
        ]
    )
    return resp.choices[0].message["content"].strip()






@app.route("/api/parrot_status", methods=["GET"])
def parrot_status():
    bucket_name = BUCKET_NAME
    words = load_all_words_from_gcs(bucket_name)
    level = evaluate_level_with_gpt(words)
    recommended = recommend_words_by_level(level)
    return jsonify({
        "level": level,
        "recommended_words": recommended
    })


@app.route("/api/run_process", methods=['POST'])
def process_word():
    try:
        input_text = request.json.get('word', '').strip()
        if not input_text:
            return jsonify({"error": "ì…ë ¥ëœ ë‹¨ì–´ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400

        safe_text = sanitize(input_text)

        # 1. TTS ìƒì„± + ì¬ìƒ + GCS ì—…ë¡œë“œ
        tts_and_play(input_text, safe_text)

        # 2. ë…¹ìŒ + ì €ì¥ + GCS ì—…ë¡œë“œ
        record_and_upload(safe_text)

        # 3. ëª¨ë¸ ë¡œë“œ
        model_path = 'parrot_speech_model.h5'
        if not os.path.exists(model_path):
            label_encoder = train_and_save_model()
        else:
            model = tf.keras.models.load_model(model_path)
            label_encoder = LabelEncoder()
            label_encoder.fit(os.listdir(audio_dir))

        # 4. ë¶„ë¥˜
        new_audio_file = os.path.join(os.path.expanduser("~"), f"{safe_text}.wav")
        predicted_word = classify_new_audio(model, new_audio_file, label_encoder)

        # ë°œìŒ ì •í™•ë„
        reference_audio = os.path.join(os.path.expanduser("~"), f"EX_{safe_text}.mp3")
        accuracy = compare_pronunciation(reference_audio, new_audio_file)
    
        # 5. GPT í”¼ë“œë°± ìƒì„±
        feedback = get_feedback_from_gpt(predicted_word, accuracy)

        # 6. ê²°ê³¼ ë°˜í™˜
        return jsonify({
            "input_word": input_text,
            "predicted_word": predicted_word,
            "accuracy": round(accuracy, 3),
            "feedback": feedback
        })

    except Exception as e:
        return jsonify({"error": str(e)}), 500
    

@app.route("/api/repeat", methods=['POST'])
def repeat_word():
    try:
        input_text = request.json.get('word', '').strip()
        if not input_text:
            return jsonify({"error": "ì…ë ¥ëœ ë‹¨ì–´ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400
        
        safe_text = sanitize(input_text)

        tts_repeat(input_text, safe_text)

        return jsonify({"repeat_result" : "ë°˜ë³µ í•™ìŠµ ì™„ë£Œ"})
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500


if __name__ == "__main__":
    app.run(debug=True, host="0.0.0.0", port=5000)
